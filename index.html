<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Petr Spelda</title>
  <style type="text/css">body{margin:40px auto;max-width:800px;line-height:1.6;font-family:Open Sans,Arial;font-size:20px;color:#454545;padding:0 10px}h1,h2,h3{line-height:1.2}</style>
 </head>
 <body>
  <img src="img.png">
  <header><h1>Petr Spelda</h1></header>  
  <p>I am an Assistant Professor at the Department of Security Studies, Charles University, Prague.</p>
  <p>I am interested in safe machine learning and the means to achieve it. Most of my works deal with inductive inference in various learning frameworks. I tend to believe that the formal study of inductive inference is important for the safety of artificial intelligence.</p>
  <p>I am writing a book on AI alignment and (social) preference learning.</p>
  <p>I collaborate with <a href="https://scholar.google.cz/citations?hl=en&user=20EtxoQAAAAJ&sortby=pubdate" target="_blank">Vit Stritecky</a>, my colleague from Charles, and <a href="https://www.johnsymons.net/" target="_blank">John Symons</a> from The University of Kansas. I am also a fellow at the <a href="https://i2s-research.ku.edu/center-cyber-social-dynamics-ccsd" target="_blank">Center for Cyber-Social Dynamics</a> at KU.</p>
  <p>My ORCID is <a href="https://orcid.org/0000-0003-4199-645X" target="_blank">0000-0003-4199-645X</a>.</p>
  <p>You can contact me at petr [dot] spelda [at] fsv [dot] cuni [dot] cz</p>
  <hr>
  <h3>Papers:</h3>
   <p><a href="https://www.sciencedirect.com/science/article/pii/S187775032400245X/pdfft?md5=a32ba2792febaa3dc65a1b93843386a5&pid=1-s2.0-S187775032400245X-main.pdf" target="_blank">Learnability of State Spaces of Physical Systems is Undecidable</a>, <em>Journal of Computational Science</em> (forthcoming), DOI:<a href="https://doi.org/10.1016/j.jocs.2024.102452" target="_blank">10.1016/j.jocs.2024.102452</a>, with Vit Stritecky.</p>
   <p><a href="https://link.springer.com/content/pdf/10.1007/s11229-024-04702-z.pdf" target="_blank">Why and How to Construct an Epistemic Justification of Machine Learning?</a>, <em>Synthese</em> (2024). DOI:<a href="https://doi.org/10.1007/s11229-024-04702-z" target="_blank">10.1007/s11229-024-04702-z</a>, with Vit Stritecky.</p>
   <p><a href="https://social-epistemology.com/wp-content/uploads/2024/05/spelda-_stritecky_symons-_reply_schurz_serrc_5-6-2024.pdf" target="_blank">On the Need for Multiple, Independent Fact-Checking and Scoring Facilities: A Reply to Gerhard Schurz</a>, <em>Social Epistemology Review and Reply Collective</em> (2024). <a href="https://social-epistemology.com/2024/05/06/on-the-need-for-multiple-independent-fact-checking-and-scoring-facilities-a-reply-to-schurz-petr-spelda-vit-striteck-john-symons/" target="_blank">URL</a>, with Vit Stritecky and John Symons.</p>
   <p><a href="https://www.tandfonline.com/doi/epdf/10.1080/02691728.2023.2252763" target="_blank">No-Regret Learning Supports Voters’ Competence</a>, <em>Social Epistemology</em> (2023). DOI:<a href="https://doi.org/10.1080/02691728.2023.2252763" target="_blank">10.1080/02691728.2023.2252763</a>, with Vit Stritecky and John Symons.<br>Gerhard Schurz's <a href="https://social-epistemology.com/2023/12/28/enhancement-of-voters-competence-based-on-meta-inductive-learning-a-reply-to-spelda-stritecky-and-symons-gerhard-schurz/" target="_blank">response</a>.</p>
   <p><a href="https://rdcu.be/cWY1p" target="_blank">Expanding Observability via Human-Machine Cooperation</a>, <em>Axiomathes/Global Philosophy</em> (2022). DOI:<a href="https://doi.org/10.1007/s10516-022-09636-0" target="_blank">10.1007/s10516-022-09636-0</a>, with Vit Stritecky.</p>
   <p><a href="https://dl.acm.org/doi/pdf/10.1145/3444691" target="_blank">Human Induction in Machine Learning: A Survey of the Nexus</a>, <em>ACM Computing Surveys</em> (2021). DOI:<a href="https://doi.org/10.1145/3444691" target="_blank">10.1145/3444691</a>, with Vit Stritecky.</p>
   <p><a href="https://philpapers.org/archive/SPEWCA-3.pdf" target="_blank">What Can Artificial Intelligence Do for Scientific Realism?</a>, <em>Axiomathes/Global Philosophy</em> (2020). DOI:<a href="https://doi.org/10.1007/s10516-020-09480-0" target="_blank">10.1007/s10516-020-09480-0</a>, with Vit Stritecky.</p>
   <p><a href="https://philpapers.org/archive/SPETFO-7.pdf" target="_blank">The Future of Human-Artificial Intelligence Nexus and its Environmental Costs</a>, <em>Futures</em> (2020). DOI:<a href="https://doi.org/10.1016/j.futures.2020.102531" target="_blank">10.1016/j.futures.2020.102531</a>, with Vit Stritecky.</p>
   <p><a href="https://rdcu.be/4XvB" target="_blank">Machine learning, inductive reasoning, and reliability of generalisations</a>, <em>AI & SOCIETY</em> (2020). DOI:<a href="https://doi.org/10.1007/s00146-018-0860-6" target="_blank">10.1007/s00146-018-0860-6</a>.</p>
  <hr>
  <h3>Papers under review on:</h3>
   <p>AI alignment safety bounds</p>
   <p>Transformers’ in-context learning</p>
   <p>No-regret machine learning lifecycle</p>
   <p>Security practices in AI</p>
  <hr>
  <h3>Papers in preparation on:</h3>
   <p>Computational complexity of inductive inference</p>
  <hr>
  <h3>Earlier papers:</h3>
   <p><a href="https://cjir.iir.cz/index.php/cjir/article/view/184" target="_blank">An Analysis of the Electronic Jihad’s Activity in the Social Media Environment</a>, <em>Czech Journal of International Relations</em> (2017), with Vit Stritecky.</p>
   <p><a href="https://cejiss.org/establishing-the-complexity-of-the-islamic-state-s-visual-propaganda-0" target="_blank">Establishing the Complexity of the Islamic State’s Visual Propaganda</a>, <em>Central European Journal of International and Security Studies</em> (2017), with Vit Stritecky.</p>
  <hr>
  <p align="center" style="font-size:15px">last update: 2024-09-27</p>
  <p align="center" style="font-size:15px">&#120512;</p>
 </body>
</html>
